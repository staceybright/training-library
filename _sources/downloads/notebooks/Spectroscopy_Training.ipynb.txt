{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python with HST Spectral Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> A very brief introduction to HST spectral data </b>\n",
    "\n",
    "For HST spectral data, there are four types of files:\n",
    "* raw \n",
    "    * COS: `rawtag`, `rawaccum`, `rawacq`\n",
    "    * STIS: `raw`, `tag`, `wav`\n",
    "* support\n",
    "    * `asn`, `spt`, `trl`, and more\n",
    "* intermediate\n",
    "    * `corrtag`, `crj`, `flt`, and more\n",
    "* products\n",
    "    * `x1d`, `x1dsum`\n",
    "\n",
    "Raw data has undergone no processing besides generic conversion from spacecraft data to FITS. Support files contain information about spacecraft telemetry (spt), exposures that should be associated (asn), pipeline processing (trl), etc. Intermediate products are files produced by each instrumentâ€™s calibration pipeline on the way to extracting a spectrum.  Products are fully calibrated, extracted 1-D spectra and typically have `x1d` in the extension. See the Instrument Data Handbooks for a full list of all data file types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieving the Required Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***First, make a directory in your central store to put your data in.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```cd /user/myname\n",
    "mkdir spect_training```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`cd spect_training`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 options for obtaining the data necessary for this tutorial. For individuals working through this assignment, we recommend using Option 2 to gain some experience working with MAST (the Mikulski Archive for Space Telescopes). If you are working through this in a group during a 1 hr training session, Option 1 of copying the files from a training directory on central store is recommended so that more time is focused on the spectroscopy than on resolving any difficulties with MAST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> Option 1: Copy from directory on central store </b>\n",
    "\n",
    "Note that when using this option it is possible that the file headers have become out of date with respect to what the calibration pipelines are expecting (particularly calcos, since it is under active development). This can cause problems with the portions of this tutorial where you run the data through the pipelines.\n",
    "\n",
    "`cp /grp/hst/riab/training/spectroscopy/*.fits .`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Option 2: Download data from MAST </b>\n",
    "\n",
    "To retrieve STIS data by its filename, simply enter the name in \"Dataset\" field in a [MAST search](http://archive.stsci.edu/hst/search.php). For COS data, however, you must search by the individual dataset's association name (more info [here](http://www.stsci.edu/hst/cos/documents/handbooks/datahandbook/ch2_cos_data5.html#460268)).\n",
    "\n",
    "***Retrieve two datasets, lbgu17qnq (association lbgu17010) and o8k401010 from the archive.*** Be sure to retrieve both un-calibrated and calibrated products. Note that each instrument on HST (past and present) is assigned a letter of the alphabet, and all data files produced by that instrument begin with this letter. These are l for COS and o for STIS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we will assume that the data are located in the same directory where you are running this notebook. If not, cd into the directory where the data are located. Note that this is important for later, as trying to run the calstis pipeline from elsewhere can cause problems where it cannot find the necessary reference files.\n",
    "\n",
    "First, let's look at the primary headers and identify some important parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "from astropy.io import fits\n",
    "cos_raw_a = \"lbgu17qnq_rawtag_a.fits\"\n",
    "cos_raw_b = \"lbgu17qnq_rawtag_b.fits\"\n",
    "stis_raw = \"o8k401010_raw.fits\" \n",
    "cos_hdr0 = fits.getheader(cos_raw_a, 0)\n",
    "cos_hdr0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Print the STIS header as well.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get individual header keywords. These are not case-specific in astropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "print(\"DETECTOR: \", cos_hdr0[\"DETECTOR\"])\n",
    "print(\"detector: \", cos_hdr0[\"detector\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some useful information about the datasets. ***Use a loop like the one below, but add any other keywords you think should be included. Make sure the keywords are identical between instruments.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hdr in [cos_hdr0, stis_hdr0]:\n",
    "    try:\n",
    "        print(hdr[\"instrument\"])\n",
    "    except KeyError:\n",
    "        print(hdr[\"primesi\"])\n",
    "    for key in [\"detector\", \"obsmode\", \"opt_elem\", \"targname\"]:\n",
    "        print(\"{0}: {1}\".format(key, hdr[key]))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between ACCUM and TIME-TAG? Let's look at the structure of each raw dataset to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "print(fits.info(cos_raw_a), \"\\n\")\n",
    "print(fits.info(stis_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get pertinent information of a FITS Table by looking at the column definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "with fits.open(cos_raw_a) as hdulist:\n",
    "    data1 = hdulist[1].data\n",
    "print(data1.names)\n",
    "print(data1.columns)\n",
    "print(data1.columns[0])\n",
    "print(data1.columns[0].unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calibration\n",
    "There is a calibration pipeline for each instrument. For COS and STIS, they are CalCOS and CalSTIS. The pipelines themselves have very limited optional arguments, and very few will effect the data. Most of the ways to change how data is calibrated is accessed by editing header keywords in the raw files. \n",
    "\n",
    "All of the reference files used by the calibration pipelines are located in central storage, and the pipelines themselves look to environment variables to find them. If you have not already done so, you will need to set these environment variables now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "import os\n",
    "#Note the environment variable names begin with their respective instrument letters\n",
    "#i.e., o and l for STIS and COS, respectively\n",
    "os.environ[\"oref\"] = '/grp/crds/hst/references/hst/'\n",
    "os.environ[\"lref\"] = '/grp/crds/hst/references/hst/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "from stistools import calstis\n",
    "import calcos\n",
    "print(\"CalCOS version: {0}\".format(calcos.__version__))\n",
    "print(\"CalCOS vdate: {0}\".format(calcos.__vdate__))\n",
    "print(\"CalSTIS version: {0}\".format(calstis.__version__))\n",
    "print(\"CalSTIS vdate: {0}\".format(calstis.__vdate__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "calstis.calstis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "calcos.calcos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already received calibrated products from the archive, but sometimes you may decide to turn certain calibration switches on or off to modify data. Let's try turning off background subtraction switch, `BACKCORR`, then re-calibrating the data. It's a good idea to print to the screen/capture the trailer file that a pipeline creates- it shows step-by-step records of how the data were calibrated and will record any errors that occur. You will need to specify a different output directory to make sure that the pipelines will not overwrite the data you already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "for cosfile in [cos_raw_a, cos_raw_b]:\n",
    "    print(\"Before, {0} BACKCORR={1}\".format(cosfile, fits.getval(cosfile,\"BACKCORR\")))\n",
    "    with fits.open(cosfile, mode=\"update\") as hdulist:\n",
    "        hdr0 = hdulist[0].header\n",
    "        hdr0.set(\"BACKCORR\", \"OMIT\")\n",
    "    print(\"After, {0} BACKCORR={1}\".format(cosfile, fits.getval(cosfile,\"BACKCORR\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`mkdir cos_backcorr_omit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "cos_asn='lbgu17010_asn.fits'\n",
    "calcos.calcos(cos_asn, outdir=\"cos_backcorr_omit\")\n",
    "\n",
    "#If you copied the data files from the central store directory instead of downloading them from MAST, it is possible\n",
    "#that the header keywords are out-of-date with respect to what the current version of calcos expects. You can either\n",
    "#go back and download the datasets from MAST, or use the following command to copy a previously processed data set\n",
    "#from central store\n",
    "\n",
    "#cp /grp/hst/riab/training/spectroscopy/cos_backcorr_omit/* /user/myname/spect_training/cos_backcorr_omit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Change the BACKCORR switch for the STIS data and calibrate the data.  You mut first create the output directory for CalSTIS.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to change BACKCORR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`mkdir stis_backcorr_omit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the STIS raw file, and be sure to specify a trailing slash for the output directory.\n",
    "\n",
    "#Make sure that you are running this from the same directory where the STIS data files are located\n",
    "#Otherwise, calstis may not be able to find the necessary reference files. An output of \"0\" means that calstis\n",
    "#succeeded, while an output of \"1\" means that it failed. The argument verbose=True can be added to print more details.\n",
    "\n",
    "calstis.calstis(stis_raw, outroot=\"stis_backcorr_omit/\")\n",
    "\n",
    "#cp /grp/hst/riab/training/spectroscopy/stis_backcorr_omit/* /user/myname/spect_training/stis_backcorr_omit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corrtag` files are very useful, but they are only produced for COS data. Instead, let's look at the unmodified `x1d` products for both COS and STIS. ***Explore the 1st extension data for the original COS and STIS `x1d` files, looking at the columns and names as we did before.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "orig_cos_x1dfile = \"lbgu17qnq_x1d.fits\"\n",
    "orig_stis_x1dfile = \"o8k401010_x1d.fits\"\n",
    "cos_x1d_orig = fits.getdata(orig_cos_x1dfile, 1)\n",
    "stis_x1d_orig = fits.getdata(orig_stis_x1dfile, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x1d` files can have strange formats. Let's fix that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "print(cos_x1d_orig[\"wavelength\"].shape)\n",
    "print(cos_x1d_orig[\"segment\"])\n",
    "print(stis_x1d_orig[\"wavelength\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the COS x1d file contains two spectra, one each for the A and B segments of the FUV detector, while the STIS x1d file contains a single spectrum. Both files store the wavelength and flux as 2D arrays. The following cell will combine the 2 COS spectra, and collapse the various arrays to 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "import numpy as np\n",
    "cos_wl_orig = np.concatenate((cos_x1d_orig[\"wavelength\"][1], cos_x1d_orig[\"wavelength\"][0]))\n",
    "cos_flux_orig = np.concatenate((cos_x1d_orig[\"flux\"][1], cos_x1d_orig[\"flux\"][0]))\n",
    "stis_wl_orig = stis_x1d_orig[\"wavelength\"].flatten()\n",
    "stis_flux_orig = stis_x1d_orig[\"flux\"].flatten()\n",
    "print(cos_wl_orig.shape)\n",
    "print(stis_wl_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Read in the BACKCORR=OMIT COS and STIS data and assign the wavelength and flux to arrays.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the COS data that has been calibrated with `BACKCORR=PERFORM` to `BACKCORR=OMIT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (20,7)\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "ax1.plot(cos_wl_new, cos_flux_new, color=\"lightseagreen\", label=\"WAVECORR=OMIT\")\n",
    "ax1.plot(cos_wl_orig, cos_flux_orig, color=\"royalblue\", label=\"WAVECORR=PERFORM\")\n",
    "ax1.legend(loc=\"best\")\n",
    "ax2.plot(cos_wl_new, cos_flux_orig-cos_flux_new, color=\"royalblue\")\n",
    "ax2.set_xlabel(\"Wavelength [$\\AA$]\")\n",
    "ax1.set_ylabel(\"Flux [ergs/s/cm$^2$/$\\AA$]\")\n",
    "ax2.set_ylabel(\"Flux [ergs/s/cm$^2$/$\\AA$]\")\n",
    "ax1.set_title(\"COS {0} BACKCORR=PERFORM\".format(cos_hdr0[\"targname\"]))\n",
    "ax2.set_title(\"BACKCORR=PERFORM - BACKCORR=OMIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now make a similar plot for STIS.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating Data\n",
    "***Make a very simple plot with both the COS and STIS spectra.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plt.plot instead of plt.subplots\n",
    "# e.g. plt.plot(wl, flux, color=...)\n",
    "\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly comparing two spectra in wavelength space cannot be done quantitatively unless both datasets have the same wavelength scale. Interpolating one spectrum onto another's wavelength scale will allow you to do far more useful calculations such as dividing, subtracting, etc. ***Follow the example below to perform a linear interpolation of the STIS x1d file onto the wavelength scale of the COS x1d (use the original files, not the BACKCORR=OMIT files).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#flux2_interpolated = np.interp(wavel1, wavel2, flux2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now divide the two spectra by each other to see where the two differ. Make a plot of the product.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing Data\n",
    "The COS data we have is at a much higher resolution than that of STIS. ***Smooth the original COS data with a boxcar filter. Try 3 different box sizes: 6, 11, and 21. Make a plot of the original and all smoothed spectra. (Hint: try a loop) (Double hint: try xlim(1220, 1245) and ylim(-0.1e-12, 0.7e-12)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from stsci.convolve import boxcar\n",
    "#smoothed_flux = boxcar(flux, (boxcar_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the signal to noise ratio (S/N)\n",
    "The signal-to-noise ratio, S/N or SNR (although SNR is also used for supernova remnant in astronomy), is an important statistic of spectra. Signal can be approximated with a low-order polynomial fit to a continuum region where there are no absorption or emission features. Noise can be approximated as the standard deviation of the fit subtracted from the data. ***Smooth the COS data using boxcar=6, and STIS data using boxcar=2. Then, follow the example below to determine the average SNR for the COS and STIS data.***\n",
    "\n",
    "Hint: Make sure to perform your fit and S/N calculation over a line-free region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#poly2 = np.polyfit(wavelength_region, smoothed_flux_region, 2)\n",
    "#fit2 = np.poly1d(poly2)\n",
    "#ycalc = fit2(wavelength_region)\n",
    "#noise = np.std(smoothed_flux_region - ycalc)\n",
    "#signal = np.average(ycalc)\n",
    "#snr = signal / noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
